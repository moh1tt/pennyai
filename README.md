# PennyAI

**PennyAI** is an end-to-end data pipeline and analysis platform designed to help traders and investors make smarter decisions on penny stocks. It ingests Reddit posts, enriches them with market data, and provides actionable insights using AI-driven summarization.

---

## ğŸš€ Features

- **Automated Data Pipeline**  
  - Fetches posts from Reddit and financial data from Yahoo Finance daily.
  - Cleans, processes, and stores data in DuckDB and Parquet formats.
  - Fully automated daily ingestion using GitHub Actions.

- **AI-Powered Summarization**  
  - Leverages **LangChain** with **Groq LLM** to summarize top Reddit posts and comments.
  - Helps identify trending penny stocks and market sentiment.

- **Flexible Frontend Options**  
  - **React + Next.js** dashboard for a modern web interface.
  - **Streamlit** app for quick deployment and interactive analytics.
  
- **API Integration**  
  - Flask + Uvicorn backend exposing endpoints to serve processed data and summaries.

---

## ğŸ—‚ Project Structure

```
pennyai/
â”œâ”€â”€ backend/                # Data pipeline and API backend
â”‚   â”œâ”€â”€ data/               # Raw and processed datasets
â”‚   â”œâ”€â”€ main.py             # Main pipeline runner
â”‚   â”œâ”€â”€ server.py           # Flask/Uvicorn API server
â”‚   â””â”€â”€ scripts/            # Data ingestion & processing scripts
â”œâ”€â”€ frontend/               # React + Next.js dashboard
â”œâ”€â”€ streamlit-frontend/     # Streamlit alternative frontend
â”œâ”€â”€ .github/workflows/      # GitHub Actions for daily ingestion
â”œâ”€â”€ pyproject.toml          # Python dependencies
â””â”€â”€ uv.lock                 # Environment lock for uv
```

---

## âš¡ Getting Started

### 1. Environment Setup

PennyAI uses **uv** for environment management.  
```bash
uv install
uv activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. API Keys Required
You need three API keys:
- **Reddit API Key 1**
- **Reddit API Key 2**
- **Groq API Key** (for LLM summarization)

### 4. Run Data Pipeline
```bash
python backend/main.py
```

### 5. Run the App

#### Streamlit (Current Deployment)
```bash
streamlit run streamlit-frontend/app.py
```

#### React + Next.js (Optional)
```bash
cd frontend
npm install
npm run dev
```

### 6. Automated Daily Ingestion
The pipeline runs automatically every day using GitHub Actions:  
`.github/workflows/daily_ingest.yml`

---

## ğŸ”‘ How It Works

1. **Reddit Ingestion:**  
   Fetches posts and comments related to penny stocks.

2. **Financial Enrichment:**  
   Enriches data with ticker info from Yahoo Finance.

3. **Processing & Storage:**  
   Processes raw data into LLM-ready datasets and stores them in DuckDB & Parquet.

4. **Summarization:**  
   Groq LLM summarizes top posts and comments for actionable insights.

5. **Dashboard:**  
   Visualizes trends, summaries, and key stock information for decision-making.

---

## ğŸ–¼ Screenshots

_Streamlit frontend screenshot_  
![PennyAI Streamlit](pennyai-home.png)

---

## ğŸ›  Tech Stack

- **Backend:** Python, Flask, Uvicorn, DuckDB, LangChain, Groq LLM  
- **Frontend:** React, Next.js, TailwindCSS or Streamlit  
- **Data Storage:** Parquet, DuckDB  
- **CI/CD:** GitHub Actions  

---

## âœ¨ Future Improvements

- Add real-time sentiment scoring.  
- Integrate more financial APIs for richer datasets.  
- Enhance the Next.js dashboard with interactive charts.  

---

## ğŸ‘¨â€ğŸ’» Author

Made with â¤ï¸ by **Mohit Appari**  
- [LinkedIn](https://www.linkedin.com/in/moh1tt)  
- [Email](mailto:moh1tt.vercel.app)

